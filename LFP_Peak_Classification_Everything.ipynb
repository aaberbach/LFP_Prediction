{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "#from fastai.text import *\n",
    "from fastai.vision import *\n",
    "from fastai.utils.mem import *\n",
    "#from fastai.tabular import *\n",
    "import scipy.signal as s\n",
    "#import pyts\n",
    "from itertools import chain \n",
    "from fastai.callbacks import *\n",
    "import sklearn.metrics as smetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the random seed for everything being used with fastai.\n",
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) # Python\n",
    "    if use_cuda: \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/LFP_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(path/\"lfp_labels_new_data.csv\", index_col = \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/\"model_fr_lfp_new.csv\")\n",
    "df = df.iloc[:len(labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avgPNA\"] = np.array([df.PNA1, df.PNA2, df.PNA3, df.PNA4, df.PNA5]).mean(0)\n",
    "df[\"avgPNC\"] = np.array([df.PNC1, df.PNC2, df.PNC3, df.PNC4, df.PNC5]).mean(0)\n",
    "df[\"avgITN\"] = np.array([df.ITN1, df.ITN2, df.ITN3, df.ITN4, df.ITN5]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to store a single input item in the dataset.\n",
    "#Stores a time series of every variable passed to it, does not contain the label.\n",
    "#Shape (1, num_back, num_vars)\n",
    "class TimeWindow(ItemBase):\n",
    "    def __init__(self, time_window):\n",
    "        time_window = np.copy(time_window)\n",
    "        self.obj = (time_window)\n",
    "        self.data = torch.Tensor(time_window)\n",
    "        self.data = self.data[None]\n",
    "        \n",
    "    def to_one(self): return self.data\n",
    "    \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"A time points plus\"\n",
    "    \n",
    "#Contains all of the inputs for the data, as well as the capability to label the inputs.\n",
    "class TimeWindowList(ItemList):\n",
    "    _label_cls = CategoryList\n",
    "    def __init__(self, items, num_back, data_input, **kwargs):\n",
    "        self.its = items\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.num_back = num_back\n",
    "        self.data_input = data_input\n",
    "        self.copy_new.append(\"data_input\")\n",
    "        self.copy_new.append(\"num_back\")\n",
    "        \n",
    "    #Returns the input time series starting at index i.\n",
    "    def get(self, i):\n",
    "        i = self.items[i]\n",
    "        return TimeWindow(self.data_input[i - self.num_back : i, :-1])\n",
    "    \n",
    "    def reconstruct(self, t:Tensor):\n",
    "        return TimeWindow(t)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    #Called to create a LabelList for the data.\n",
    "    def label_from_func(self, func:Callable, label_cls:Callable=None, **kwargs)->'LabelList':\n",
    "        \"Apply `func` to every input to get its label.\"\n",
    "        return self._label_from_list([self.label_func(o) for o in range(0, len(self))], label_cls=label_cls, **kwargs)\n",
    "    \n",
    "    #Determines the label of input i based on the next_above list passed to this class.\n",
    "    def label_func(self, i):\n",
    "        return int(self.data_input[self.items[i], -1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, out_size, num_features):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        #Kernels of size (n, 1) to allow GradCam for individual variables/features.\n",
    "        self.convs_2d = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size = (9, 1), padding = (4, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(64, 128, kernel_size = (7, 1), stride = (2, 1), padding = (3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(128, 1, kernel_size = (1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "        \n",
    "        #Combines all features for GradCam over time.\n",
    "        self.convs_1d = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 64, kernel_size = (5), padding = (2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv1d(64, 128, kernel_size = (5), stride = 2, padding = (2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "        \n",
    "        #Takes CNN features and turns them into the output.\n",
    "        self.lins = nn.Sequential(\n",
    "            nn.Linear(1280, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(640),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(640, 320),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(320),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(160),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(160, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(32, out_size),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs_2d(x)\n",
    "        x = torch.squeeze(x, dim = 1)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.convs_1d(x)\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "        x = self.lins(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNan(num):\n",
    "    return num != num\n",
    "\n",
    "#Returns accuracy where the truth value is 1 (peak is above).\n",
    "def true_acc(input:Tensor, targs:Tensor)->Rank0Tensor:\n",
    "    \"Computes accuracy with `targs` when `input` is bs * n_classes.\"\n",
    "    n = targs.shape[0]\n",
    "    input = input.argmax(dim=-1).view(n,-1)\n",
    "    targs = targs.view(n,-1)\n",
    "    mask = targs == 1\n",
    "    acc = float((input[mask]==targs[mask]).float().mean())\n",
    "    if isNan(acc):\n",
    "        return torch.Tensor([0.0]).cuda().mean()\n",
    "    else:\n",
    "        return (input[mask]==targs[mask]).float().mean()\n",
    "\n",
    "#Returns accuracy where the truth value is 0 (peak is bellow).\n",
    "def false_acc(input:Tensor, targs:Tensor)->Rank0Tensor:\n",
    "    \"Computes accuracy with `targs` when `input` is bs * n_classes.\"\n",
    "    n = targs.shape[0]\n",
    "    input = input.argmax(dim=-1).view(n,-1)\n",
    "    targs = targs.view(n,-1)\n",
    "    mask = targs == 0\n",
    "    acc = float((input[mask]==targs[mask]).float().mean())\n",
    "    if isNan(acc):\n",
    "        return torch.Tensor([0.0]).cuda().mean()\n",
    "    else:\n",
    "        return (input[mask]==targs[mask]).float().mean()\n",
    "\n",
    "kappa = KappaScore()\n",
    "auc_roc = AUROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the train and test data sets out of the five folds.\n",
    "def make_cross_data(splits, test_num, num_back, data_input, seed):\n",
    "    valid_num = (test_num + 1) % 5\n",
    "    \n",
    "    #Concatenates together all of the splits that are not the test set.\n",
    "    #The validation split is put first.\n",
    "    inds = splits[valid_num]\n",
    "    for i in range(5):\n",
    "        if i != valid_num and i != test_num:\n",
    "            inds = np.concatenate((inds, splits[i]))\n",
    "            \n",
    "    random_seed(seed, True)\n",
    "    train_data = (TimeWindowList(inds, num_back, data_input)\n",
    "                .split_by_idx(range(len(splits[0])))\n",
    "                .label_from_func(lambda x: x)\n",
    "                .databunch(bs = 64, num_workers = 0))\n",
    "    \n",
    "    #Creates the data out of the test split for evaluation.\n",
    "    random_seed(seed, True)\n",
    "    test_data = (TimeWindowList(splits[test_num], num_back, data_input)\n",
    "                .split_none()\n",
    "                .label_from_func(lambda x: x)\n",
    "                .databunch(bs = 64, num_workers = 0))\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs given metrics on given model with the given data.\n",
    "#Also performs kappa and auc_roc, as well as returns the confusion matrix.\n",
    "def get_scores(learn, data, metrics):\n",
    "    learn.data = data\n",
    "    interp = ClassificationInterpretation.from_learner(learn, DatasetType.Train)\n",
    "    preds = np.array(interp.preds)\n",
    "    kappa = smetrics.cohen_kappa_score(interp.y_true, preds.argmax(1))\n",
    "    auc = smetrics.roc_auc_score(interp.y_true, preds[:, 1])\n",
    "    return [interp.confusion_matrix()] + [metric(interp.preds, interp.y_true) for metric in metrics] + [kappa, auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs 5 fold cross validation.\n",
    "#Returns the evaluations for each fold.\n",
    "def do_cross_valid(num_vars, indexes, data_input, num_back, train_metrics, test_metrics, wd, lr, epochs, base_name = None, num_start = 1, loss_func = None):\n",
    "    res = []#Stores the evaluation scores for each fold.\n",
    "    \n",
    "    #Makes indexes divisible by 5 so it can be split evenly.\n",
    "    indexes = np.array(indexes)[:-(len(indexes) % 5)]\n",
    "    #Gets the five folds.\n",
    "    splits = np.split(np.array(indexes), 5)\n",
    "    \n",
    "    for i in range(5):\n",
    "        num_label = num_start + i\n",
    "        train_data, test_data = make_cross_data(splits, i, num_back, data_input, num_label)\n",
    "        \n",
    "        #Creates the model.\n",
    "        random_seed(num_label, True)\n",
    "        if loss_func != None:\n",
    "            learn = Learner(train_data, CNNModel(2, num_vars), loss_func = loss_func, metrics = train_metrics, wd = wd)\n",
    "        else:\n",
    "            learn = Learner(train_data, CNNModel(2, num_vars), metrics = train_metrics, wd = wd)\n",
    "        \n",
    "        #Decides where the model will be saved or if it should be saved.\n",
    "        random_seed(num_label, True)\n",
    "        if base_name != None:\n",
    "            name = base_name + str(num_label)\n",
    "        else:\n",
    "            name = \"model\"\n",
    "            \n",
    "        #Used  for early stopping and saving the epoch with the best validation loss.\n",
    "        callbacks = [EarlyStoppingCallback(learn, patience = 5),\n",
    "                    SaveModelCallback(learn, every='improvement', monitor='valid_loss', name=name)]\n",
    "        \n",
    "        #Fits the model.\n",
    "        random_seed(num_label, True)\n",
    "        learn.fit_one_cycle(epochs, lr, callbacks= callbacks)\n",
    "        \n",
    "        #Evaluates the model.\n",
    "        res.append(get_scores(learn, test_data, test_metrics))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_percent(arr):\n",
    "    arr = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_back = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PNA1', 'PNA2', 'PNA3', 'PNA4', 'PNA5', 'PNC1', 'PNC2', 'PNC3', 'PNC4',\n",
       "       'PNC5', 'ITN1', 'ITN2', 'ITN3', 'ITN4', 'ITN5', 'rawLFP', 'filtLFP',\n",
       "       'hilbLFP', 'avgPNA', 'avgPNC', 'avgITN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores all input except for filtLFP and hilbLFP.\n",
    "data_input = np.stack([df[columns[i]] for i in range(16)] + [df[columns[i]] for i in range(-3, 0)]  + [labels.next_above], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.696939287506272"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percent of input that is labeled as above threshold.\n",
    "(len(np.where(np.array(labels.next_above) == 1)[0]) / len(df)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the indexes in data_input where it is only 3 or less ms until the next peak.\n",
    "#Right now only using df[:-30000] so test set is kept, don't know if necessary.\n",
    "indexes = [i for i in range(100, len(df) - 30000) if labels.time_until_peak[i] <= 3 and labels.time_until_peak[i] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33552"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics calculated each epoch during training.\n",
    "train_metrics = [accuracy, true_acc, false_acc, kappa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics used for evaluation of each fold.\n",
    "test_metrics = [accuracy, true_acc, false_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unaltered Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)\n",
    "train_data = (TimeWindowList(indexes, num_back, data_input)\n",
    "            .split_by_idx(range(10000))\n",
    "            .label_from_func(lambda x: x)\n",
    "            .databunch(bs = 64, num_workers = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(train_data, CNNModel(2, num_vars), wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Helps to choose a learning rate.\n",
    "#Choose where there is steep decline and then a little back from that.\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_acc</th>\n",
       "      <th>false_acc</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.416340</td>\n",
       "      <td>0.857824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.389623</td>\n",
       "      <td>0.364822</td>\n",
       "      <td>0.857824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.333495</td>\n",
       "      <td>0.392454</td>\n",
       "      <td>0.860507</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031940</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335064</td>\n",
       "      <td>0.359617</td>\n",
       "      <td>0.860507</td>\n",
       "      <td>0.010290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031940</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.331693</td>\n",
       "      <td>0.521731</td>\n",
       "      <td>0.762444</td>\n",
       "      <td>0.618728</td>\n",
       "      <td>0.773784</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.333291</td>\n",
       "      <td>0.329447</td>\n",
       "      <td>0.860954</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037180</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.325972</td>\n",
       "      <td>0.301058</td>\n",
       "      <td>0.878540</td>\n",
       "      <td>0.192147</td>\n",
       "      <td>0.987472</td>\n",
       "      <td>0.291799</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.309916</td>\n",
       "      <td>0.302410</td>\n",
       "      <td>0.873472</td>\n",
       "      <td>0.141443</td>\n",
       "      <td>0.990666</td>\n",
       "      <td>0.229680</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.314447</td>\n",
       "      <td>0.299160</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.134187</td>\n",
       "      <td>0.989859</td>\n",
       "      <td>0.226650</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.301806</td>\n",
       "      <td>0.303852</td>\n",
       "      <td>0.869598</td>\n",
       "      <td>0.082821</td>\n",
       "      <td>0.997989</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.303881</td>\n",
       "      <td>0.328905</td>\n",
       "      <td>0.867958</td>\n",
       "      <td>0.075575</td>\n",
       "      <td>0.998225</td>\n",
       "      <td>0.128791</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.292797</td>\n",
       "      <td>0.301149</td>\n",
       "      <td>0.872876</td>\n",
       "      <td>0.113502</td>\n",
       "      <td>0.995817</td>\n",
       "      <td>0.194675</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.296378</td>\n",
       "      <td>0.300411</td>\n",
       "      <td>0.871982</td>\n",
       "      <td>0.108573</td>\n",
       "      <td>0.996520</td>\n",
       "      <td>0.181266</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.306671</td>\n",
       "      <td>0.300313</td>\n",
       "      <td>0.871535</td>\n",
       "      <td>0.115151</td>\n",
       "      <td>0.993229</td>\n",
       "      <td>0.196493</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.297774</td>\n",
       "      <td>0.298418</td>\n",
       "      <td>0.873770</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>0.991185</td>\n",
       "      <td>0.230495</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.282067</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.150198</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.290652</td>\n",
       "      <td>0.300618</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.128528</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.216494</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.286387</td>\n",
       "      <td>0.298021</td>\n",
       "      <td>0.874367</td>\n",
       "      <td>0.150499</td>\n",
       "      <td>0.989921</td>\n",
       "      <td>0.242989</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.283002</td>\n",
       "      <td>0.299837</td>\n",
       "      <td>0.871833</td>\n",
       "      <td>0.118566</td>\n",
       "      <td>0.993686</td>\n",
       "      <td>0.197287</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.277175</td>\n",
       "      <td>0.298685</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.132521</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>0.219569</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.294055</td>\n",
       "      <td>0.876155</td>\n",
       "      <td>0.170562</td>\n",
       "      <td>0.987307</td>\n",
       "      <td>0.272466</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.292955</td>\n",
       "      <td>0.296058</td>\n",
       "      <td>0.873025</td>\n",
       "      <td>0.135413</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.223428</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.277617</td>\n",
       "      <td>0.297123</td>\n",
       "      <td>0.872876</td>\n",
       "      <td>0.131598</td>\n",
       "      <td>0.991869</td>\n",
       "      <td>0.217925</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.274934</td>\n",
       "      <td>0.294648</td>\n",
       "      <td>0.875410</td>\n",
       "      <td>0.155601</td>\n",
       "      <td>0.989123</td>\n",
       "      <td>0.256442</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.283829</td>\n",
       "      <td>0.299206</td>\n",
       "      <td>0.872280</td>\n",
       "      <td>0.131555</td>\n",
       "      <td>0.991338</td>\n",
       "      <td>0.215288</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.41633981466293335.\n",
      "Better model found at epoch 1 with valid_loss value: 0.3648223876953125.\n",
      "Better model found at epoch 3 with valid_loss value: 0.3596172630786896.\n",
      "Better model found at epoch 5 with valid_loss value: 0.3294469714164734.\n",
      "Better model found at epoch 6 with valid_loss value: 0.3010578751564026.\n",
      "Better model found at epoch 8 with valid_loss value: 0.29915952682495117.\n",
      "Better model found at epoch 14 with valid_loss value: 0.2984178364276886.\n",
      "Better model found at epoch 17 with valid_loss value: 0.29802149534225464.\n",
      "Better model found at epoch 20 with valid_loss value: 0.2940550446510315.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      56.00% [14/25 04:15<03:20]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_acc</th>\n",
       "      <th>false_acc</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.472178</td>\n",
       "      <td>0.398370</td>\n",
       "      <td>0.872578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396911</td>\n",
       "      <td>0.374539</td>\n",
       "      <td>0.872578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329301</td>\n",
       "      <td>0.288902</td>\n",
       "      <td>0.878987</td>\n",
       "      <td>0.050742</td>\n",
       "      <td>0.996237</td>\n",
       "      <td>0.114357</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335054</td>\n",
       "      <td>0.298139</td>\n",
       "      <td>0.875261</td>\n",
       "      <td>0.023330</td>\n",
       "      <td>0.997558</td>\n",
       "      <td>0.057206</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.319085</td>\n",
       "      <td>0.311877</td>\n",
       "      <td>0.875410</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.998196</td>\n",
       "      <td>0.054364</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320363</td>\n",
       "      <td>0.291075</td>\n",
       "      <td>0.874665</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.320223</td>\n",
       "      <td>0.286660</td>\n",
       "      <td>0.877347</td>\n",
       "      <td>0.036406</td>\n",
       "      <td>0.997893</td>\n",
       "      <td>0.080692</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.306299</td>\n",
       "      <td>0.289561</td>\n",
       "      <td>0.884501</td>\n",
       "      <td>0.127979</td>\n",
       "      <td>0.989732</td>\n",
       "      <td>0.224659</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.313832</td>\n",
       "      <td>0.271381</td>\n",
       "      <td>0.888227</td>\n",
       "      <td>0.222940</td>\n",
       "      <td>0.978356</td>\n",
       "      <td>0.327390</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.306119</td>\n",
       "      <td>0.279956</td>\n",
       "      <td>0.881073</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.294059</td>\n",
       "      <td>0.274265</td>\n",
       "      <td>0.883905</td>\n",
       "      <td>0.100873</td>\n",
       "      <td>0.993471</td>\n",
       "      <td>0.192983</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.306139</td>\n",
       "      <td>0.274982</td>\n",
       "      <td>0.888674</td>\n",
       "      <td>0.182323</td>\n",
       "      <td>0.985480</td>\n",
       "      <td>0.293739</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.295027</td>\n",
       "      <td>0.282545</td>\n",
       "      <td>0.890611</td>\n",
       "      <td>0.181297</td>\n",
       "      <td>0.988098</td>\n",
       "      <td>0.296615</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.278610</td>\n",
       "      <td>0.283184</td>\n",
       "      <td>0.882116</td>\n",
       "      <td>0.086596</td>\n",
       "      <td>0.992858</td>\n",
       "      <td>0.176738</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105' class='' max='105', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105/105 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.3983704447746277.\n",
      "Better model found at epoch 1 with valid_loss value: 0.37453922629356384.\n",
      "Better model found at epoch 2 with valid_loss value: 0.28890153765678406.\n",
      "Better model found at epoch 6 with valid_loss value: 0.28665968775749207.\n",
      "Better model found at epoch 8 with valid_loss value: 0.2713812291622162.\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='18' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      72.00% [18/25 05:27<02:07]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_acc</th>\n",
       "      <th>false_acc</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.446495</td>\n",
       "      <td>0.385662</td>\n",
       "      <td>0.860954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.372611</td>\n",
       "      <td>0.324661</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.056371</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>0.110927</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332676</td>\n",
       "      <td>0.302033</td>\n",
       "      <td>0.880179</td>\n",
       "      <td>0.191191</td>\n",
       "      <td>0.985734</td>\n",
       "      <td>0.294853</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.321172</td>\n",
       "      <td>0.353416</td>\n",
       "      <td>0.863934</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.316625</td>\n",
       "      <td>0.306274</td>\n",
       "      <td>0.877347</td>\n",
       "      <td>0.102488</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.196258</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.321275</td>\n",
       "      <td>0.307081</td>\n",
       "      <td>0.877347</td>\n",
       "      <td>0.102449</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>0.192844</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.328359</td>\n",
       "      <td>0.306814</td>\n",
       "      <td>0.876602</td>\n",
       "      <td>0.101752</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.189661</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.311442</td>\n",
       "      <td>0.327516</td>\n",
       "      <td>0.864083</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.309315</td>\n",
       "      <td>0.295223</td>\n",
       "      <td>0.876304</td>\n",
       "      <td>0.100203</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.188850</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>0.322267</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.276833</td>\n",
       "      <td>0.976528</td>\n",
       "      <td>0.378213</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.313406</td>\n",
       "      <td>0.304050</td>\n",
       "      <td>0.887183</td>\n",
       "      <td>0.209765</td>\n",
       "      <td>0.990832</td>\n",
       "      <td>0.331418</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.308849</td>\n",
       "      <td>0.295394</td>\n",
       "      <td>0.882861</td>\n",
       "      <td>0.139199</td>\n",
       "      <td>0.997650</td>\n",
       "      <td>0.257012</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.304655</td>\n",
       "      <td>0.292279</td>\n",
       "      <td>0.878241</td>\n",
       "      <td>0.105227</td>\n",
       "      <td>0.998512</td>\n",
       "      <td>0.205478</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.296143</td>\n",
       "      <td>0.294513</td>\n",
       "      <td>0.875261</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.173260</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.285875</td>\n",
       "      <td>0.313110</td>\n",
       "      <td>0.871386</td>\n",
       "      <td>0.060941</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>0.127674</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.291163</td>\n",
       "      <td>0.297184</td>\n",
       "      <td>0.871833</td>\n",
       "      <td>0.070001</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.291071</td>\n",
       "      <td>0.294253</td>\n",
       "      <td>0.874963</td>\n",
       "      <td>0.088581</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>0.171284</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.287539</td>\n",
       "      <td>0.293912</td>\n",
       "      <td>0.874665</td>\n",
       "      <td>0.088558</td>\n",
       "      <td>0.998363</td>\n",
       "      <td>0.169309</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105' class='' max='105', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105/105 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.3856618106365204.\n",
      "Better model found at epoch 1 with valid_loss value: 0.32466062903404236.\n",
      "Better model found at epoch 2 with valid_loss value: 0.3020326793193817.\n",
      "Better model found at epoch 8 with valid_loss value: 0.29522284865379333.\n",
      "Better model found at epoch 12 with valid_loss value: 0.29227885603904724.\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_acc</th>\n",
       "      <th>false_acc</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.505481</td>\n",
       "      <td>0.416609</td>\n",
       "      <td>0.861848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386787</td>\n",
       "      <td>0.374364</td>\n",
       "      <td>0.861848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.347382</td>\n",
       "      <td>0.311470</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.050485</td>\n",
       "      <td>0.998093</td>\n",
       "      <td>0.102959</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331164</td>\n",
       "      <td>0.324824</td>\n",
       "      <td>0.863040</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.320656</td>\n",
       "      <td>0.329938</td>\n",
       "      <td>0.864978</td>\n",
       "      <td>0.018501</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.042829</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323955</td>\n",
       "      <td>0.306042</td>\n",
       "      <td>0.863189</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.311175</td>\n",
       "      <td>0.284847</td>\n",
       "      <td>0.883905</td>\n",
       "      <td>0.182180</td>\n",
       "      <td>0.990131</td>\n",
       "      <td>0.299628</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.314158</td>\n",
       "      <td>0.291225</td>\n",
       "      <td>0.874069</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.995770</td>\n",
       "      <td>0.170092</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.311090</td>\n",
       "      <td>0.297707</td>\n",
       "      <td>0.872876</td>\n",
       "      <td>0.072134</td>\n",
       "      <td>0.997969</td>\n",
       "      <td>0.143982</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.308257</td>\n",
       "      <td>0.292288</td>\n",
       "      <td>0.890462</td>\n",
       "      <td>0.309662</td>\n",
       "      <td>0.972228</td>\n",
       "      <td>0.429723</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.295810</td>\n",
       "      <td>0.280207</td>\n",
       "      <td>0.884501</td>\n",
       "      <td>0.172068</td>\n",
       "      <td>0.992286</td>\n",
       "      <td>0.293106</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.296709</td>\n",
       "      <td>0.280051</td>\n",
       "      <td>0.879881</td>\n",
       "      <td>0.136085</td>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.242324</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.302914</td>\n",
       "      <td>0.290205</td>\n",
       "      <td>0.873920</td>\n",
       "      <td>0.079744</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>0.155301</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.293449</td>\n",
       "      <td>0.282328</td>\n",
       "      <td>0.875559</td>\n",
       "      <td>0.101391</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.187994</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.298206</td>\n",
       "      <td>0.289767</td>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.102012</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.186504</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.288481</td>\n",
       "      <td>0.282883</td>\n",
       "      <td>0.878689</td>\n",
       "      <td>0.123688</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.227445</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.289558</td>\n",
       "      <td>0.279756</td>\n",
       "      <td>0.882414</td>\n",
       "      <td>0.154838</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.269731</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.286048</td>\n",
       "      <td>0.284631</td>\n",
       "      <td>0.874069</td>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>0.164151</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.287276</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.872578</td>\n",
       "      <td>0.066256</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>0.133162</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.284646</td>\n",
       "      <td>0.278973</td>\n",
       "      <td>0.879285</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.992809</td>\n",
       "      <td>0.240630</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.289820</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>0.875112</td>\n",
       "      <td>0.094594</td>\n",
       "      <td>0.996495</td>\n",
       "      <td>0.176382</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.275019</td>\n",
       "      <td>0.278548</td>\n",
       "      <td>0.880477</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>0.994047</td>\n",
       "      <td>0.245057</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.280243</td>\n",
       "      <td>0.279508</td>\n",
       "      <td>0.879136</td>\n",
       "      <td>0.129252</td>\n",
       "      <td>0.994230</td>\n",
       "      <td>0.230821</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.279456</td>\n",
       "      <td>0.278301</td>\n",
       "      <td>0.881520</td>\n",
       "      <td>0.158672</td>\n",
       "      <td>0.991517</td>\n",
       "      <td>0.270045</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.275225</td>\n",
       "      <td>0.279916</td>\n",
       "      <td>0.880179</td>\n",
       "      <td>0.139379</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>0.244204</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.416608989238739.\n",
      "Better model found at epoch 1 with valid_loss value: 0.374363511800766.\n",
      "Better model found at epoch 2 with valid_loss value: 0.31146958470344543.\n",
      "Better model found at epoch 5 with valid_loss value: 0.3060416281223297.\n",
      "Better model found at epoch 6 with valid_loss value: 0.2848474383354187.\n",
      "Better model found at epoch 10 with valid_loss value: 0.2802067697048187.\n",
      "Better model found at epoch 11 with valid_loss value: 0.2800508141517639.\n",
      "Better model found at epoch 16 with valid_loss value: 0.27975594997406006.\n",
      "Better model found at epoch 19 with valid_loss value: 0.27897289395332336.\n",
      "Better model found at epoch 21 with valid_loss value: 0.2785484790802002.\n",
      "Better model found at epoch 23 with valid_loss value: 0.27830126881599426.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='21' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      84.00% [21/25 06:29<01:14]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_acc</th>\n",
       "      <th>false_acc</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.467097</td>\n",
       "      <td>0.398577</td>\n",
       "      <td>0.874367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.421078</td>\n",
       "      <td>0.379531</td>\n",
       "      <td>0.874367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349655</td>\n",
       "      <td>0.293620</td>\n",
       "      <td>0.888674</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.989256</td>\n",
       "      <td>0.258724</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.319143</td>\n",
       "      <td>0.286807</td>\n",
       "      <td>0.885693</td>\n",
       "      <td>0.119958</td>\n",
       "      <td>0.993182</td>\n",
       "      <td>0.199628</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.327675</td>\n",
       "      <td>0.286534</td>\n",
       "      <td>0.885544</td>\n",
       "      <td>0.131016</td>\n",
       "      <td>0.989055</td>\n",
       "      <td>0.224634</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.309443</td>\n",
       "      <td>0.300490</td>\n",
       "      <td>0.887928</td>\n",
       "      <td>0.220565</td>\n",
       "      <td>0.976683</td>\n",
       "      <td>0.322704</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.315354</td>\n",
       "      <td>0.281194</td>\n",
       "      <td>0.891356</td>\n",
       "      <td>0.216001</td>\n",
       "      <td>0.981393</td>\n",
       "      <td>0.328476</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.312667</td>\n",
       "      <td>0.306987</td>\n",
       "      <td>0.876453</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.030386</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.311865</td>\n",
       "      <td>0.286958</td>\n",
       "      <td>0.882414</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>0.997116</td>\n",
       "      <td>0.130474</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.286629</td>\n",
       "      <td>0.885544</td>\n",
       "      <td>0.091073</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.168034</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.310712</td>\n",
       "      <td>0.272145</td>\n",
       "      <td>0.891803</td>\n",
       "      <td>0.178904</td>\n",
       "      <td>0.989406</td>\n",
       "      <td>0.289592</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.301889</td>\n",
       "      <td>0.291420</td>\n",
       "      <td>0.886289</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>0.995661</td>\n",
       "      <td>0.187293</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.309853</td>\n",
       "      <td>0.274296</td>\n",
       "      <td>0.894188</td>\n",
       "      <td>0.208082</td>\n",
       "      <td>0.985194</td>\n",
       "      <td>0.336366</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.272906</td>\n",
       "      <td>0.893890</td>\n",
       "      <td>0.189971</td>\n",
       "      <td>0.989334</td>\n",
       "      <td>0.309363</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.307151</td>\n",
       "      <td>0.272418</td>\n",
       "      <td>0.891058</td>\n",
       "      <td>0.156087</td>\n",
       "      <td>0.992967</td>\n",
       "      <td>0.259189</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.307086</td>\n",
       "      <td>0.272103</td>\n",
       "      <td>0.895082</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.988378</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.299536</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.889568</td>\n",
       "      <td>0.123434</td>\n",
       "      <td>0.995926</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.295981</td>\n",
       "      <td>0.275037</td>\n",
       "      <td>0.888077</td>\n",
       "      <td>0.114710</td>\n",
       "      <td>0.995898</td>\n",
       "      <td>0.206404</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.297969</td>\n",
       "      <td>0.274640</td>\n",
       "      <td>0.891058</td>\n",
       "      <td>0.146244</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>0.254665</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.278450</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.883010</td>\n",
       "      <td>0.075885</td>\n",
       "      <td>0.997451</td>\n",
       "      <td>0.134882</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.281153</td>\n",
       "      <td>0.272644</td>\n",
       "      <td>0.892996</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.282705</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105' class='' max='105', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105/105 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.39857685565948486.\n",
      "Better model found at epoch 1 with valid_loss value: 0.37953129410743713.\n",
      "Better model found at epoch 2 with valid_loss value: 0.293620228767395.\n",
      "Better model found at epoch 3 with valid_loss value: 0.28680720925331116.\n",
      "Better model found at epoch 4 with valid_loss value: 0.28653445839881897.\n",
      "Better model found at epoch 6 with valid_loss value: 0.2811938226222992.\n",
      "Better model found at epoch 10 with valid_loss value: 0.27214521169662476.\n",
      "Better model found at epoch 15 with valid_loss value: 0.27210307121276855.\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = do_cross_valid(19, indexes, data_input, num_back, train_metrics, test_metrics, 1e-4, 1e-2, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.986763, 0.013237])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0] / arr[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.750894, 0.249106])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1] / arr[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[5740,   77],\n",
       "         [ 630,  209]], dtype=int64),\n",
       "  tensor(0.8938),\n",
       "  tensor(0.2491),\n",
       "  tensor(0.9868),\n",
       "  0.32852023061341085,\n",
       "  0.8646546444466437],\n",
       " [array([[5605,  102],\n",
       "         [ 690,  259]], dtype=int64),\n",
       "  tensor(0.8810),\n",
       "  tensor(0.2729),\n",
       "  tensor(0.9821),\n",
       "  0.343859524217898,\n",
       "  0.8561207161892213],\n",
       " [array([[5766,   46],\n",
       "         [ 737,  107]], dtype=int64),\n",
       "  tensor(0.8824),\n",
       "  tensor(0.1268),\n",
       "  tensor(0.9921),\n",
       "  0.18284139529691268,\n",
       "  0.861166878137405],\n",
       " [array([[5713,   21],\n",
       "         [ 739,  183]], dtype=int64),\n",
       "  tensor(0.8858),\n",
       "  tensor(0.1985),\n",
       "  tensor(0.9963),\n",
       "  0.28937638372236774,\n",
       "  0.8647510719255013],\n",
       " [array([[5663,   73],\n",
       "         [ 697,  223]], dtype=int64),\n",
       "  tensor(0.8843),\n",
       "  tensor(0.2424),\n",
       "  tensor(0.9873),\n",
       "  0.32109127286908457,\n",
       "  0.8777336880722819]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
